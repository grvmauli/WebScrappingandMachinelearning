{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code the customer review data is collected from the html through the process of the web scrapping. The three selected categories are Atomotive, Fashion and Gym. The customer review is collected with the Star rating . This star rating is used to decide the positive and negative nature of the review.The star rating 4 and above is consider as positive and below that is consider as negative. The textual review is also collected for data minig purpose and the performance of text classification algorithm is evaluted in the later part of the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the required librabries in the assignament.\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import html\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import cross_val_score, RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#Decalaration of the variables\n",
    "starRating=[]\n",
    "natureOfReview=[]\n",
    "reviewComment=[]\n",
    "Fashion_review_data = []\n",
    "Automotive_review_data = []\n",
    "Gym_review_data = []\n",
    "#Create a Gaussian Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we are collecting the HTML data from the given URL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will collect all the data of star rating and review comments from the URL \n",
    "def get_rating_status (URLReview):\n",
    "    \n",
    "    URLpage = requests.get(URLReview) #The URL of the comapny review is accessed through request \n",
    "    reviewSoup = BeautifulSoup(URLpage.content, 'html.parser')#BeautifulreviewSoup is used to parse the data\n",
    "    trimhtml = reviewSoup.find(id='all')# It will trim data under the tag id= all in html\n",
    "    reviewtrim=trimhtml.find_all(class_='review')# All the class with review name is accessed\n",
    "    \n",
    "    for t in reviewtrim:           # Each elecment of the class review name is accessed\n",
    "        ratingStar = t.find('img')    # this will search for the tag with img\n",
    "        if ratingStar:               # It will check for the img tag\n",
    "            temp = ratingStar['alt'] # It will search for the alt tag\n",
    "            starRating.append(temp)  #This is to store the star rating\n",
    "            if(temp=='5-star' or temp=='4-star' ): #This will check if the review is positive or negative\n",
    "                natureOfReview.append(1)         #For positive review 1 will be stored in the list\n",
    "            else:\n",
    "                natureOfReview.append(0)        #For negative review 0 will be stored in the list\n",
    "        #The review comment is stored in the another list with lower case (Preprocessing)\n",
    "        reviewComment.append(t.find(class_='review-text').get_text().lower())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this function the catagory URL will be input and then it wil access the review of the comapnies in particular catagory\n",
    "def Catagory_data (URLcatagory):\n",
    "    URLcatagorypage = requests.get(URLcatagory) #The URL of the category accessed through request  \n",
    "    catagorysoup = BeautifulSoup(URLcatagorypage.content, 'html.parser')#BeautifulreviewSoup is used to parse the data\n",
    "    trimhtmllink = catagorysoup.find(id='all')# It will trim data under the tag id= all in html\n",
    "    reviewtrimlink =trimhtmllink.find_all('p')# All the p tag data is accessed\n",
    "    for t in reviewtrimlink:         #For each data with p tag is accessed\n",
    "        ratingStar = t.find('a')     # searching for the tag a\n",
    "        if ratingStar:               #this is the condition for a tag\n",
    "            temp = ratingStar['href']#Accessing the data under href tag\n",
    "            URL = 'http://mlg.ucd.ie/modules/yalp/'+ temp #The URL of companies review is generated  \n",
    "            get_rating_status(URL)  #Call the function with the URL of companies review to collect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This functio will generate the CSV file of the data collected from the html with category and data to be stored as an input\n",
    "def Generating_CSV (category,zip_data_to_write):\n",
    "    \n",
    "    with open('ReviewData'+category+'.csv', 'w', encoding='utf-8') as csvfile: #creating the csv file with customized name\n",
    "        fileInWritemode = csv.writer(csvfile) #openeing CSV file in write mode\n",
    "        count=0        # counter decalraition\n",
    "        for word in zip_data_to_write: #accessing the data to write in csv\n",
    "            if count != 0:            #This will start from the second row\n",
    "                fileInWritemode.writerow(word) #Writing row\n",
    "            else:                     #generating column with heading\n",
    "                fileInWritemode.writerow(['Star Rating','Nature of Rating','Review Comment'])#Names of the column\n",
    "                count = count+1     #Update the counter value\n",
    "    csvfile.close()   #save and closing the file\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection of data and generating csv file for Automotive category\n",
    "Automotive_URL='http://mlg.ucd.ie/modules/yalp/automotive_list.html'\n",
    "Catagory_data (Automotive_URL) #calling function with category URL \n",
    "\n",
    "Automotive_review_data.append(starRating) #Appending the data in the list from the function with star rating\n",
    "Automotive_review_data.append(natureOfReview) #Appending the data in the list from the function with Nature of Review\n",
    "Automotive_review_data.append(reviewComment) #Appending the data in the list from the function with Review comments\n",
    "zip_Automotive_data_to_write = zip(*Automotive_review_data) # converting the list into zip file\n",
    "\n",
    "# clearing the list decalred globally\n",
    "starRating=[]\n",
    "natureOfReview=[]\n",
    "reviewComment=[]\n",
    "\n",
    "Generating_CSV ('Automotive',zip_Automotive_data_to_write)# calling the function to genrate the csv file with category and data to be written as argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection of data and generating csv file for Fashion category\n",
    "Fashion_URL='http://mlg.ucd.ie/modules/yalp/fashion_list.html'\n",
    "Catagory_data (Fashion_URL)  #calling function with category URL\n",
    "\n",
    "Fashion_review_data.append(starRating) #Appending the data in the list from the function with star rating\n",
    "Fashion_review_data.append(natureOfReview) #Appending the data in the list from the function with Nature of Review\n",
    "Fashion_review_data.append(reviewComment) #Appending the data in the list from the function with Review comments\n",
    "zip_Fashion_data_to_write = zip(*Fashion_review_data)       # converting the list into zip file\n",
    "\n",
    "# clearing the list decalred globally\n",
    "starRating=[]\n",
    "natureOfReview=[]\n",
    "reviewComment=[]\n",
    "\n",
    "Generating_CSV ('Fashion',zip_Fashion_data_to_write)# calling the function to genrate the csv file with category and data to be written as argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection of data and generating csv file for Gym category\n",
    "Gym_URL='http://mlg.ucd.ie/modules/yalp/gym_list.html'\n",
    "Catagory_data (Gym_URL) #calling function with category URL\n",
    "\n",
    "Gym_review_data.append(starRating) #Appending the data in the list from the function with star rating\n",
    "Gym_review_data.append(natureOfReview) #Appending the data in the list from the function with Nature of Review\n",
    "Gym_review_data.append(reviewComment) #Appending the data in the list from the function with Review comments\n",
    "zip_Gym_data_to_write = zip(*Gym_review_data)         # converting the list into zip file\n",
    "\n",
    "# clearing the list decalred globally\n",
    "starRating=[]\n",
    "natureOfReview=[]\n",
    "reviewComment=[]\n",
    "\n",
    "Generating_CSV ('Gym',zip_Gym_data_to_write)# calling the function to genrate the csv file with category and data to be written as argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section the text data collected from the review comment is preprocessed.On part of preprocessing is to convert the data in lower case is already done when storing the review comment in the csv file.\n",
    "The text preprocessing is an important step in improving the performance of the bag of words model. The steps which are included in text preprocessing are as given below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Case conversion:- The incoming data is stored in lower case in csv file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Filter short term:- In this case the words which are less than 4 are filtered out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Filter Stop words:- In the vectorizer the all the english stop words are filtered using english                           command\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Filter infrequent word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Along with this in order give more weight to more important terms term frequency–inverse document frequency (TF-IDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_preprocessing(FileName,catagory):\n",
    "    CombineCsv_data = pd.read_csv(FileName) #Reading the combine csv data file'\n",
    "    Reviewtext = CombineCsv_data[\"Review Comment\"] #fetching the data from the column Review Comment\n",
    "    natureOfComment = CombineCsv_data[\"Nature of Rating\"] #fetching the data from the column Nature of Rating\n",
    "    \n",
    "    # Tokenization of the data with preprocessing steps\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\",min_df = 4)\n",
    "    vectorizedData = vectorizer.fit_transform(Reviewtext)\n",
    "    \n",
    "    #Dividing the data into traning and testing dataset \n",
    "    trainingData, testingData, natureOfComment_train, natureOfComment_test = train_test_split(vectorizedData, natureOfComment, test_size=0.3)\n",
    "    \n",
    "    print(\"Number of samples in traning data  is %d\"%trainingData.shape[0]+\" for \"+ catagory )\n",
    "    print(\"Number of testing samples is %d \"%testingData.shape[0]+\" for \"+ catagory )\n",
    "    \n",
    "    #Classification model of Logistic Regression\n",
    "    logisticRegr = LogisticRegression()\n",
    "    logisticRegr.fit(trainingData,natureOfComment_train)#Training the model with train data\n",
    "    predicted = logisticRegr.predict(testingData)       # Predicting the test data\n",
    "    print(\"Accuracy for \"+catagory+ \" review from logistic regression = %.2f\" % accuracy_score(natureOfComment_test, predicted) ) #Accuracy of the model\n",
    "    print(\"Precision for \"+catagory+ \" review from logistic regression = %.2f\" % precision_score(natureOfComment_test, predicted, pos_label=1) )#Precision of the Model\n",
    "    print(\"Recall for \"+catagory+ \" review from logistic regression = %.2f\" % recall_score(natureOfComment_test, predicted, pos_label=1) )# Recall of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the text classification the text is used to identify the the nature of the speech.In this case we will try to identify whether the review is positive or negative. In order to achieve this we have to train a model with some training data . Then the testing data is used for predection.There are different classification algorithms which can be used to classify the algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assingment the Logistic Regression algorithm is used. Logstic Regression uses sigmoid function for the predection.The sigmoid function maps any real value to value between 0 to 1. This strategy makes the model more accurate for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in traning data  is 1399 for Automotive\n",
      "Number of testing samples is 600  for Automotive\n",
      "Accuracy for Automotive review from logistic regression = 0.92\n",
      "Precision for Automotive review from logistic regression = 0.91\n",
      "Recall for Automotive review from logistic regression = 0.95\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Data_preprocessing('ReviewDataAutomotive.csv','Automotive')\n",
    "\n",
    "\n",
    "#data_train_auto, data_test_auto, target_train_auto, target_test_auto = train_test_split(Xdata, target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different evaluation strategy which can be used to evaluate the performance of the buld model.For this assignment the Accrracy is choosed for performance of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in traning data  is 1399 for Fashion\n",
      "Number of testing samples is 600  for Fashion\n",
      "Accuracy for Fashion review from logistic regression = 0.88\n",
      "Precision for Fashion review from logistic regression = 0.85\n",
      "Recall for Fashion review from logistic regression = 0.97\n"
     ]
    }
   ],
   "source": [
    "Data_preprocessing('ReviewDataFashion.csv','Fashion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This accuracy shows how accurate the predection of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in traning data  is 1399 for Gym\n",
      "Number of testing samples is 600  for Gym\n",
      "Accuracy for Gym review from logistic regression = 0.85\n",
      "Precision for Gym review from logistic regression = 0.82\n",
      "Recall for Gym review from logistic regression = 0.96\n"
     ]
    }
   ],
   "source": [
    "Data_preprocessing('ReviewDataGym.csv','Gym')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above value shows that the algorithm is well trained as it gives high value of accuracy. The predictions made by the algorithm is highly accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the following is calculation of the performance of the model with training data of one catagory and testing data of another catagory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collecting data from Automotive Catagory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "csv_data_Auto = pd.read_csv('ReviewDataAutomotive.csv') #Reading the combine csv data file'\n",
    "ReviewData_Auto = csv_data_Auto[\"Review Comment\"] #fetching the data from the column Review Comment\n",
    "ratingNature_Auto = csv_data_Auto[\"Nature of Rating\"] #fetching the data from the column Nature of Rating\n",
    "\n",
    "# Tokenization of the data with preprocessing steps\n",
    "vectorizer_Auto = TfidfVectorizer(stop_words=\"english\",min_df = 4)\n",
    "preprocessedData_Auto = vectorizer_Auto.fit_transform(ReviewData_Auto)\n",
    "\n",
    "data_train_Auto, data_test_Auto, target_train_Auto, target_test_Auto = train_test_split(preprocessedData_Auto, ratingNature_Auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collecting data from Fashion Catagory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data_Fash = pd.read_csv('ReviewDataFashion.csv')#Reading the combine csv data file'\n",
    "ReviewData_Fash = csv_data_Fash[\"Review Comment\"] #fetching the data from the column Review Comment\n",
    "ratingNature_Fash = csv_data_Fash[\"Nature of Rating\"] #fetching the data from the column Nature of Rating\n",
    "\n",
    "# Tokenization of the data with preprocessing steps\n",
    "preprocessedData_Fash = vectorizer_Auto.transform(ReviewData_Fash)\n",
    "\n",
    "data_train_Fash, data_test_Fash, target_train_Fash, target_test_Fash = train_test_split(preprocessedData_Fash, ratingNature_Fash, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collecting data from Gym Catagory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data_Gym = pd.read_csv('ReviewDataGym.csv') #Reading the combine csv data file'\n",
    "ReviewData_Gym = csv_data_Gym[\"Review Comment\"] #fetching the data from the column Review Comment\n",
    "ratingNature_Gym = csv_data_Gym[\"Nature of Rating\"] #fetching the data from the column Nature of Rating\n",
    "\n",
    "# Tokenization of the data with preprocessing steps\n",
    "preprocessedData_Gym = vectorizer_Auto.transform(ReviewData_Gym)\n",
    "\n",
    "data_train_Gym, data_test_Gym, target_train_Gym, target_test_Gym = train_test_split(preprocessedData_Gym, ratingNature_Gym)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1. Performance of Logistic Regression model with training data of Automotive and testing data of Fashion and Gym catagory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Automotive with Fashion = 0.87\n"
     ]
    }
   ],
   "source": [
    "AutoLis=[]\n",
    "logisticRegr = LogisticRegression()\n",
    "\n",
    "logisticRegr.fit(data_train_Auto,target_train_Auto) #Training the model with train data with Automotive category\n",
    "predicted_c1 = logisticRegr.predict(data_test_Fash) # Predicting the test data of Fashion\n",
    "AutoLis.append(\"Automotive Train Data\")\n",
    "AutoLis.append(\"\")\n",
    "AutoLis.append(accuracy_score(target_test_Fash, predicted_c1))\n",
    "print(\"Accuracy of Automotive with Fashion = %.2f\" % accuracy_score(target_test_Fash, predicted_c1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Automotive with Gym = 0.85\n"
     ]
    }
   ],
   "source": [
    "predicted_c2 = logisticRegr.predict(data_test_Gym) # Predicting the test data of Gym\n",
    "AutoLis.append(accuracy_score(target_test_Gym, predicted_c2))\n",
    "print(\"Accuracy of Automotive with Gym = %.2f\" % accuracy_score(target_test_Gym, predicted_c2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Performance of Logistic Regression model with training data of Fashion and testing data of Automotive and Gym catagory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Fashion with Automotive = 0.86\n"
     ]
    }
   ],
   "source": [
    "fashList=[]\n",
    "logisticRegr.fit(data_train_Fash,target_train_Fash) #Training the model with train data with Fashion category\n",
    "predicted_c1 = logisticRegr.predict(data_test_Auto) # Predicting the test data of Automotive\n",
    "fashList.append(\"Fashion Train Data\")\n",
    "fashList.append(accuracy_score(target_test_Auto, predicted_c1))\n",
    "fashList.append(\"\")\n",
    "print(\"Accuracy of Fashion with Automotive = %.2f\" % accuracy_score(target_test_Auto, predicted_c1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Fashion with Gym= 0.89\n"
     ]
    }
   ],
   "source": [
    "predicted_c1 = logisticRegr.predict(data_test_Gym) # Predicting the test data of Gym\n",
    "fashList.append(accuracy_score(target_test_Gym, predicted_c1))\n",
    "print(\"Accuracy of Fashion with Gym= %.2f\" % accuracy_score(target_test_Gym, predicted_c1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Performance of Logistic Regression model with training data of Gym and testing data of Automotive and Fashion catagory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Gym with Automotive = 0.86\n"
     ]
    }
   ],
   "source": [
    "Gymlist=[]\n",
    "logisticRegr.fit(data_train_Gym,target_train_Gym) #Training the model with train data with Gym category\n",
    "predicted_c1 = logisticRegr.predict(data_test_Auto) # Predicting the test data of Automotive\n",
    "Gymlist.append(\"Gym Train Data\")\n",
    "Gymlist.append(accuracy_score(target_test_Auto, predicted_c1))\n",
    "print(\"Accuracy of Gym with Automotive = %.2f\" % accuracy_score(target_test_Auto, predicted_c1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Gym with Fashion= 0.86\n"
     ]
    }
   ],
   "source": [
    "predicted_c1 = logisticRegr.predict(data_test_Fash) # Predicting the test data of Fashion\n",
    "Gymlist.append(accuracy_score(target_test_Fash, predicted_c1))\n",
    "Gymlist.append(\"\")\n",
    "\n",
    "print(\"Accuracy of Gym with Fashion= %.2f\" % accuracy_score(target_test_Fash, predicted_c1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Table length=4</i>\n",
       "<table id=\"table2677260037448\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>col0</th><th>col1</th><th>col2</th><th>col3</th></tr></thead>\n",
       "<thead><tr><th>str20</th><th>str21</th><th>str18</th><th>str18</th></tr></thead>\n",
       "<tr><td></td><td>Automotive Train Data</td><td>Fashion Train Data</td><td>Gym Train Data</td></tr>\n",
       "<tr><td>Automotive Test Data</td><td></td><td>0.862</td><td>0.858</td></tr>\n",
       "<tr><td>Fashion Test Data</td><td>0.8733333333333333</td><td></td><td>0.8616666666666667</td></tr>\n",
       "<tr><td>Gym Test Data</td><td>0.854</td><td>0.892</td><td></td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=4>\n",
       "        col0                  col1                col2               col3       \n",
       "       str20                 str21               str18              str18       \n",
       "-------------------- --------------------- ------------------ ------------------\n",
       "                     Automotive Train Data Fashion Train Data     Gym Train Data\n",
       "Automotive Test Data                                    0.862              0.858\n",
       "   Fashion Test Data    0.8733333333333333                    0.8616666666666667\n",
       "       Gym Test Data                 0.854              0.892                   "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from astropy.table import QTable, Table, Column\n",
    "colname=[]\n",
    "colname.append(\"\")\n",
    "colname.append(\"Automotive Test Data\")\n",
    "colname.append(\"Fashion Test Data\")\n",
    "colname.append(\"Gym Test Data\")\n",
    "arr = (colname,AutoLis ,fashList ,Gymlist)\n",
    "Table(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the table of showing Accuracy columns with the category train data and rows with the category test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of the accuracy obtained shows that even though data is trained in any catogory it can predict the data from another catagory with high accuracy. This tells that the build model is reliabel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assingment gave an insight about the different steps in any Data science project. Starting with the data extraction form the html page. During extraction process it is important to figure out the data which carrys more information. After extracting the data it is important to store it in proper format so that it can be extracted and utlize for further processing. The obtained data has need to convert into the format so that it can be evaluated(Tokenization). There are different pre processing techniques which helps to extract the necessary data. This data can be classified using some algorithms.The performance of the algorithm can be evaluated using traning data and testing data of different catagories."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
